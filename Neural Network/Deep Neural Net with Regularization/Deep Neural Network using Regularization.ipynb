{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Deep Neural Network using Regularization.ipynb","provenance":[],"authorship_tag":"ABX9TyP9UjiFMQjC3mVhwSTxImbn"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"wbPlpv0TlmJY","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nJwpGnnzlyw7","colab_type":"code","colab":{}},"source":["trainX = np.array(((0,0),(0,1),(1,0),(1,1)))\n","trainY = np.array((0,1,1,1))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cVi-xS6Nl-FK","colab_type":"code","outputId":"1093a7cb-140f-4b3c-d174-a51f386fde92","executionInfo":{"status":"ok","timestamp":1585065377499,"user_tz":-330,"elapsed":3286,"user":{"displayName":"Aayush Kumaria","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgkkVnW9tLCpbuFO2HC1elTAU8MVWUPGCffq5OeMw=s64","userId":"13603907698207247248"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["print(trainX.shape)\n","print(trainY.shape)"],"execution_count":405,"outputs":[{"output_type":"stream","text":["(4, 2)\n","(4,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8yL1HfytmDkI","colab_type":"code","outputId":"b24193aa-cfb5-4305-94ba-6dcc4ed07795","executionInfo":{"status":"ok","timestamp":1585065377500,"user_tz":-330,"elapsed":3089,"user":{"displayName":"Aayush Kumaria","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgkkVnW9tLCpbuFO2HC1elTAU8MVWUPGCffq5OeMw=s64","userId":"13603907698207247248"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["trainX = np.transpose(trainX)\n","\n","trainY = trainY.reshape(1,trainY.shape[0])\n","\n","print(trainX.shape)\n","print(trainY.shape)"],"execution_count":406,"outputs":[{"output_type":"stream","text":["(2, 4)\n","(1, 4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"a0ncBUHqmQDt","colab_type":"code","outputId":"fed9e1a3-1426-496e-a4ca-5a4dee3e23c5","executionInfo":{"status":"ok","timestamp":1585065377501,"user_tz":-330,"elapsed":2900,"user":{"displayName":"Aayush Kumaria","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgkkVnW9tLCpbuFO2HC1elTAU8MVWUPGCffq5OeMw=s64","userId":"13603907698207247248"}},"colab":{"base_uri":"https://localhost:8080/","height":118}},"source":["layers = np.array((trainX.shape[0],10,7,5,3,trainY.shape[0]))\n","\n","print(\"Model has \" +str(layers.shape[0])+ \" Layers\")\n","for i in range(1,layers.shape[0]):\n","  print(\"Layer \" +str(i)+ \" has \" +str(layers[i])+ \" Nodes\")"],"execution_count":407,"outputs":[{"output_type":"stream","text":["Model has 6 Layers\n","Layer 1 has 10 Nodes\n","Layer 2 has 7 Nodes\n","Layer 3 has 5 Nodes\n","Layer 4 has 3 Nodes\n","Layer 5 has 1 Nodes\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VGl0fsC_melQ","colab_type":"code","colab":{}},"source":["def initWeights(layers):\n","  #Random Initialization\n","\n","  L = len(layers)\n","  param={}\n","\n","  for i in range(1,L):\n","    param[\"W\"+str(i)] = np.random.randn(layers[i], layers[i-1]) *0.75\n","    param[\"b\"+str(i)] = np.zeros((layers[i],1))\n","\n","  return param"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3mB0se9tpSJ6","colab_type":"code","colab":{}},"source":["def forwardActivation(A_prev, W, b, activation):\n","\n","  Z = np.dot(W,A_prev) + b\n","\n","  if activation == \"relu\":\n","    A = np.maximum(Z,0)\n","\n","  if activation == \"sigmoid\":\n","    A = 1/(1+np.exp(-Z))\n","\n","  l_cache = (A_prev, W, b)\n","  a_cache = (A, Z)\n","  cache = (l_cache, a_cache)\n","\n","  return A, cache"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tl_78gIqoOt3","colab_type":"code","colab":{}},"source":["def forwardProp(X, param):\n","\n","  L = len(param)//2\n","  caches = []\n","  A = X\n","\n","  for i in range(1,L):\n","    A_prev = A\n","    W = param[\"W\"+str(i)]\n","    b = param[\"b\"+str(i)]\n","    A, cache = forwardActivation(A_prev, W, b, activation=\"relu\")\n","    caches.append(cache)\n","\n","  W = param[\"W\"+str(L)]\n","  b = param[\"b\"+str(L)]\n","  A_last_layer, cache = forwardActivation(A, W, b, activation=\"sigmoid\")\n","  caches.append(cache)\n","\n","  return A_last_layer, caches"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zGvyWephsRVU","colab_type":"code","colab":{}},"source":["def computeCost(m, A, Y):\n","\n","  loss = 1/-m * (Y*np.log(A)) + ((1-Y)*np.log(1-A))\n","\n","  return loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7XF5lMHjt85l","colab_type":"code","colab":{}},"source":["def computeL2Cost(m, lambd, param):\n","\n","  L = len(param)//2\n","\n","  for i in range(1,L):\n","    W = np.sum(np.square(param[\"W\" +str(i)]))\n","    #b is very small so almost negligible\n","\n","  W = W + np.sum(np.square(param[\"W\" +str(L)]))\n","\n","  l2_cost = ((lambd*W)/(2*m))\n","\n","  return l2_cost"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PyRYvSPGxkWR","colab_type":"code","colab":{}},"source":["def backwardActivation(m, dA, Y, cache, lambd, activation):\n","\n","  l_cache, a_cache = cache\n","\n","  A_prev, W, b = l_cache\n","  A, Z = a_cache\n","\n","  if activation == \"sigmoid\":\n","    dZ = dA - Y\n","\n","  if activation == \"relu\":\n","    dZ = np.multiply(dA, np.int64(A > 0))\n","\n","  dW = (np.dot(dZ,A_prev.T)/m) + ((lambd*W)/m)\n","  db = np.sum(dZ, axis=1, keepdims=True)\n","  dA_prev = np.dot(W.T,dZ)\n","\n","  return dA_prev, dW, db"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gq-6iKbTvsgW","colab_type":"code","colab":{}},"source":["def backwardProp(m, A, Y, lambd, caches):\n","\n","  grads= {}\n","  L = len(caches)\n","  m = A_last_layer.shape[1]\n","\n","  dA_current = -(np.divide(Y,A) - np.divide((1-Y),(1-A)))\n","  cache_last_layer = caches[-1]\n","\n","  dA_prev, dW, db = backwardActivation(m, dA_current, Y, cache_last_layer, lambd, activation=\"sigmoid\")\n","  grads[\"dA\" +str(L-1)] = dA_prev\n","  grads[\"dW\" +str(L)] = dW\n","  grads[\"db\" +str(L)] = db\n","\n","  for i in reversed(range(L-1)):\n","    dA_current = grads[\"dA\" +str(i+1)]\n","    cache_current_layer = cache[i]\n","\n","    dA_prev, dW, db = backwardActivation(m, dA_current, Y, cache_current_layer, lambd, activation=\"relu\")\n","    grads[\"dA\" +str(i)] = dA_prev\n","    grads[\"dW\" +str(i+1)] = dW\n","    grads[\"db\" +str(i+1)] = db \n","\n","  return grads"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ariUKYEm2S7E","colab_type":"code","colab":{}},"source":["def optimize(lr, param, grads):\n","\n","  L = len(param)//2\n","\n","  for i in range(1,L):\n","    param[\"W\" +str(i)] = param[\"W\" +str(i)] - lr*grads[\"dW\" +str(i)]\n","    param[\"b\" +str(i)] = param[\"b\" +str(i)] - lr*grads[\"db\" +str(i)]\n","\n","  return param"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e9Nw92mknwMF","colab_type":"code","outputId":"c96fa5ec-3ca8-4ffc-b3ea-00ad15635e1a","executionInfo":{"status":"ok","timestamp":1585065019484,"user_tz":-330,"elapsed":1048,"user":{"displayName":"Aayush Kumaria","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgkkVnW9tLCpbuFO2HC1elTAU8MVWUPGCffq5OeMw=s64","userId":"13603907698207247248"}},"colab":{"base_uri":"https://localhost:8080/","height":73}},"source":["lr = float(input(\"Enter the learning rate: \"))\n","iter = int(input(\"Enter the number of iterations: \"))\n","lambd = float(input(\"Enter the value of Lambda: \"))\n","m = trainX.shape[1]\n","cost_plot = []\n","\n","param = initWeights(layers)\n","#param contains W and B for each layer\n","\n","\n","for i in range(1,iter):\n","  A_last_layer, cache = forwardProp(trainX, param)\n","  #cache format = [Layer][l_cache/a_cache][Parameter]\n","\n","  cost = computeCost(m, A_last_layer, trainY)\n","  l2_cost = computeL2Cost(m, lambd, param)\n","  #L2 Regularization\n","  cost = np.sum(cost + l2_cost)\n","  if i%5 == 0:\n","    print(cost)\n","    #print(A_last_layer)\n","    cost_plot.append(cost)\n","\n","  grads = backwardProp(m, A_last_layer, trainY, lambd, cache)\n","  #grads contains dW and db for each layer\n","\n","  param = optimize(lr, param, grads)\n","  #Gradient Descent Optimizer\n","\n","plt.plot(cost_plot)\n","plt.xlabel(\"Iterations\")\n","plt.ylabel(\"Cost\")\n","plt.show()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Enter the learning rate: 0.001\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Fx0rzPke6r8N","colab_type":"code","outputId":"a5f788db-4c8a-45cc-d319-13429ec89ecb","executionInfo":{"status":"ok","timestamp":1585065806374,"user_tz":-330,"elapsed":4027,"user":{"displayName":"Aayush Kumaria","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgkkVnW9tLCpbuFO2HC1elTAU8MVWUPGCffq5OeMw=s64","userId":"13603907698207247248"}},"colab":{"base_uri":"https://localhost:8080/","height":84}},"source":["x = int(input(\"Enter the value of x: \"))\n","y = int(input(\"Enter the value of y: \"))\n","\n","if (x!=0 and x!=1) or (y!=0 and y!=1):\n","  print(\"Invalid\")\n","\n","pred = np.array((x,y))\n","pred = pred.reshape((pred.shape[0],1))\n","\n","result, cache = forwardProp(pred,param)\n","\n","print(result)\n","\n","\n","if result>0.5:\n","  result = 1\n","else:\n","  result = 0\n","\n","print(\"OR gate output is: \"+str(result))"],"execution_count":448,"outputs":[{"output_type":"stream","text":["Enter the value of x: 1\n","Enter the value of y: 1\n","[[0.5]]\n","OR gate output is: 0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pfevE4-x8Epw","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}
